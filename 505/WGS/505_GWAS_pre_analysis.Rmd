---
title: "505_WGS_pre_analysis"
author: "Ruijuan Li"
date: "8/20/2018"
output: html_document
---

### load libs
```{r}
library(tidyverse)
library(reshape2)
```

### download 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/download_array_WGS.slurm

### QC 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/QC.sh
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/trimming_array.slurm
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/QC_trimmed.sh

QC stats: 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/fastqc_extract_stats.sh 

```{r}
WGS_data <- read.csv("~/Desktop/Brassica_project/KIAT_RNA_seq/505/data/WGS_raw_data_info.csv")
WGS_data <- 
WGS_data %>% 
  dplyr::select(Sample, Yield..Mbases., X.....Q30, Mean.Quality)  

WGS_data <- WGS_data[2:239,] 
colnames(WGS_data) <- c("Sample", "Yield_in_Mb", "Q30_pct", "Mean_quality")
WGS_data$Yield_in_Mb <- gsub("\\,", "",as.character(WGS_data$Yield_in_Mb)) %>% as.numeric()
WGS_data$Q30_pct <- as.character(WGS_data$Q30_pct) %>% as.numeric()
WGS_data$Mean_quality <- as.character(WGS_data$Mean_quality) %>% as.numeric()

sapply(colnames(WGS_data)[2:4], function(i) {median(WGS_data[,i])})
sapply(colnames(WGS_data)[2:4], function(i) {min(WGS_data[,i])})
sapply(colnames(WGS_data)[2:4], function(i) {max(WGS_data[,i])})

# histogram based on reads number 
p.yeild <- 
WGS_data %>% 
  ggplot() + 
  geom_histogram(aes(x = Yield_in_Mb), binwidth = 100) 

ggsave(p.yeild, filename = "~/Desktop/p.yeild.png", width = 9, height = 4)
# read count generated by FastQC
read_stats <- read.delim("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/FastQC_Stats_238")
read_stats <- 
read_stats %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads = sum(Number_Reads)) 
dim(read_stats)

read_stats_HQ <- read.delim("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/FastQC_Stats_HQ_238")
read_stats_HQ <- 
read_stats_HQ %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads_HQ = sum(Number_Reads))  

# note sample with inconsistent yield report and fastqc read count 
stats_compare <- 
read_stats %>% 
  left_join(WGS_data) %>% 
  mutate(FastQC_calc_Mb = round(Number_Reads * 151 / 1000000, digits = 0)) %>% 
  dplyr::select(Sample, Yield_in_Mb, FastQC_calc_Mb, Number_Reads)

sum(stats_compare$Yield_in_Mb > stats_compare$FastQC_calc_Mb)
sum(stats_compare$Yield_in_Mb != stats_compare$FastQC_calc_Mb) 

stats_compare$note <- ifelse(stats_compare$Yield_in_Mb != stats_compare$FastQC_calc_Mb, "NO", "YES")

p.stats_compare <- 
stats_compare %>% 
  filter(note == "NO") %>% 
  mutate(From_DNA_center = Yield_in_Mb, From_FastQC = FastQC_calc_Mb) %>% 
  dplyr::select(Sample, From_DNA_center, From_FastQC) %>% 
  melt() %>% 
  ggplot() + 
  geom_col(aes(x = Sample, y = value, fill = variable)) + 
  theme(axis.text.x=element_blank()) + 
  ylab("Yield in Mb")

ggsave(p.stats_compare, filename = "~/Desktop/p.stats_compare.png", width = 9, height = 4)  
write.csv(stats_compare, file = "~/Desktop/stats_compare.csv") 

stats_compare <- read.csv("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/stats_compare.csv")
sample_list <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/sample_list")

Prob_samples <- 
stats_compare %>% 
  filter(note == "NO") %>% 
  dplyr::select(Sample) 

sample_list_47 <- 
sample_list %>% 
  mutate(Sample = gsub("_L003", "", V1)) %>% 
  mutate(Sample = gsub("_S.*", "", V1)) %>% 
  right_join(Prob_samples) %>% 
  dplyr::select(V1)

write.table(sample_list_47, file = "~/Desktop/sample_list_47")

# redownload 47 samples and did QC 
read_stats_47 <- read.delim("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/FastQC_Stats.tab")
read_stats_47 <- 
read_stats_47 %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads = sum(Number_Reads)) 
dim(read_stats_47)

read_stats_47_HQ <- read.delim("~/Desktop/Brassica_project/KIAT_RNA_seq/505/WGS/data/FastQC_Stats_HQ.tab")
read_stats_47_HQ <- 
read_stats_47_HQ %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads_HQ = sum(Number_Reads))  

stats_compare_47 <- 
read_stats_47 %>% 
  left_join(WGS_data) %>% 
  mutate(FastQC_calc_Mb = round(Number_Reads * 151 / 1000000, digits = 0)) %>% 
  dplyr::select(Sample, Yield_in_Mb, FastQC_calc_Mb, Number_Reads)

sum(stats_compare_47$Yield_in_Mb > stats_compare_47$FastQC_calc_Mb)
sum(stats_compare_47$Yield_in_Mb != stats_compare_47$FastQC_calc_Mb) 

read_stats_47 %>% 
  left_join(read_stats_47_HQ) %>% 
  mutate(HQ_pct = Number_Reads_HQ/Number_Reads) %>% 
  ggplot() + 
  geom_histogram(aes(x = HQ_pct))  

read_stats_summary_47 <- 
read_stats_47 %>% 
  left_join(read_stats_47_HQ) 

read_stats_summary <- 
read_stats %>% 
  left_join(read_stats_HQ) 

read_stats <- 
read_stats_summary %>% 
  anti_join(read_stats_summary_47, by = "Sample") %>% 
  rbind(read_stats_summary_47) 
```

### mapping 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/mapping_array_WGS_cabernet.slurm 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/Prep4SNPcalling.slurm

mapping stats: 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/5055751.pts-164.barbera/mapping_stats.sh 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/bwa_extract_stats.sh

```{r}
library(reshape2)

mapping_stats <- read.delim("~/Desktop/BWA_Stats.tab")

WGS_stats <- 
mapping_stats %>% 
  mutate(Sample = gsub("_L003", "", Sample)) %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  left_join(read_stats) %>% 
  mutate(Pct_HQ = Number_Reads_HQ/Number_Reads, 
         Pct_Mapped = Number_Mapped/100, 
         Pct_Unique_Mapped = Number_Unique_Mapped/Number_Reads_HQ)

WGS_stats %>% 
  dplyr::select(starts_with("Pct")) %>% 
  melt() %>% 
  ggplot() + 
  geom_histogram(aes(x = value), binwidth = 0.01) + 
  facet_wrap(~variable, nrow = 3) 
  
# note libs with low quailty, low mapping rate, and/or low unique mapping rate  
WGS_stats %>% 
  dplyr::select(Sample, starts_with("Pct")) %>% 
  filter(Pct_HQ < 0.85 | Pct_Mapped < 0.75 | Pct_Unique_Mapped < 0.4)   

# inconsistent yield and fastqc stats...   
### 4 lines ...     
```

### SNP calling 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/Bam_Split_By_Chrom.slurm 
Freebayes-parallel SNP calling: 

* some chroms require large memory, which is due to extremely high coverage for some regions on those chrom.
calculate read coverage 
sum read coverage at certain location 

plot coverage 

```{r}
# extract only regions with reasonable coverage: 
# cat i.sum | awk '$3<2500{print $1 "\t" $2 "\t" $2+1}' > i.bed
# GATK pipeline 
# cat vcfs.list | grep -v "K101" | grep -v "K133" | grep -v "SJ_290" > vcfs_235.list
```



