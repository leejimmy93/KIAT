---
title: "505_WGS_pre_analysis"
author: "Ruijuan Li"
date: "8/20/2018"
output: html_document
---

### download 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/download_array_WGS.slurm

### QC 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/QC.sh
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/trimming_array.slurm
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/QC_trimmed.sh

QC stats: 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/fastqc_extract_stats.sh

```{r}
WGS_data <- read.csv("~/Desktop/Brassica_project/KIAT_RNA_seq/505/data/WGS_raw_data_info.csv")
WGS_data <- 
WGS_data %>% 
  dplyr::select(Sample, Yield..Mbases., X.....Q30, Mean.Quality) 

WGS_data <- WGS_data[2:239,] 
colnames(WGS_data) <- c("Sample", "Yield_in_Mb", "Q30_pct", "Mean_quality")
WGS_data$Yield_in_Mb <- gsub("\\,", "",as.character(WGS_data$Yield_in_Mb)) %>% as.numeric()
WGS_data$Q30_pct <- as.character(WGS_data$Q30_pct) %>% as.numeric()
WGS_data$Mean_quality <- as.character(WGS_data$Mean_quality) %>% as.numeric()

sapply(colnames(WGS_data)[2:4], function(i) {median(WGS_data[,i])})
sapply(colnames(WGS_data)[2:4], function(i) {min(WGS_data[,i])})
sapply(colnames(WGS_data)[2:4], function(i) {max(WGS_data[,i])})

# histogram based on reads number 
hist(WGS_data$Yield_in_Mb, breaks = 100)   

# read count generated by FastQC
read_stats <- read.delim("~/Desktop/FastQC_Stats.tab")
read_stats <- 
read_stats %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads = sum(Number_Reads)) 
dim(read_stats)

read_stats_HQ <- read.delim("~/Desktop/FastQC_Stats_HQ.tab")
read_stats_HQ <- 
read_stats_HQ %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  group_by(Sample) %>% 
  summarise(Number_Reads_HQ = sum(Number_Reads))  

# note sample with inconsistent yield report and fastqc read count 
stats_compare <- 
read_stats %>% 
  left_join(WGS_data) %>% 
  mutate(FastQC_calc_Mb = round(Number_Reads * 151 / 1000000, digits = 0)) %>% 
  dplyr::select(Sample, Yield_in_Mb, FastQC_calc_Mb, Number_Reads)

sum(stats_compare$Yield_in_Mb > stats_compare$FastQC_calc_Mb)
sum(stats_compare$Yield_in_Mb != stats_compare$FastQC_calc_Mb) 

stats_compare$note <- ifelse(stats_compare$Yield_in_Mb != stats_compare$FastQC_calc_Mb, "NO", "YES")
stats_compare %>% View()

write.csv(stats_compare, file = "~/Desktop/stats_compare.csv") 
```

### mapping 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/mapping_array_WGS_cabernet.slurm 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/Prep4SNPcalling.slurm

mapping stats: 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/mapping_stats.sh 
https://github.com/leejimmy93/KIAT_cabernet/blob/master/505/bwa_extract_stats.sh

```{r}
library(reshape2)

mapping_stats <- read.delim("~/Desktop/BWA_Stats.tab")

WGS_stats <- 
mapping_stats %>% 
  mutate(Sample = gsub("_L003", "", Sample)) %>% 
  mutate(Sample = gsub("_S.*", "", Sample)) %>% 
  left_join(read_stats) %>% 
  left_join(read_stats_HQ) %>% 
  mutate(Pct_HQ = Number_Reads_HQ/Number_Reads, 
         Pct_Mapped = Number_Mapped/100,
         Pct_Unique_Mapped = Number_Unique_Mapped/Number_Reads)

WGS_stats %>% 
  dplyr::select(starts_with("Pct")) %>% 
  melt() %>% 
  ggplot() + 
  geom_histogram(aes(x = value), binwidth = 0.01) + 
  facet_wrap(~variable, nrow = 3) 
  
# note libs with low quailty, low mapping rate, and/or low unique mapping rate  
WGS_stats %>% 
  dplyr::select(Sample, starts_with("Pct")) %>% 
  filter(Pct_HQ < 0.85 | Pct_Mapped < 0.75 | Pct_Unique_Mapped < 0.4)  

# inconsistent yield and fastqc stats... 
### 4 lines ...    
```

### SNP calling 



